from sklearn.datasets import load_digits
import pandas as pd
from keras.models import Sequential 
from keras.layers import Dense 
import time
from sklearn.model_selection import train_test_split , RandomizedSearchCV , GridSearchCV , StratifiedKFold , cross_val_predict , cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
# import numpy as np

datasets = load_digits()
x = datasets.data
y = datasets.target
print(x)
print(y)
print(x.shape,y.shape)      # (1797, 64) (1797,)
print(pd.value_counts(y ,sort=False ))          # sort= False 로 하면 숫자가 순서대로 정렬됨   
# 0    178
# 1    182
# 2    177
# 3    183
# 4    181
# 5    182
# 6    181
# 7    179
# 8    174
# 9    180

''' 25퍼 미만 열 삭제 '''
columns = datasets.feature_names
# columns = x.columns
x = pd.DataFrame(x,columns=columns)
print("x.shape",x.shape)
''' 이 밑에 숫자에 얻은 feature_importances 넣고 줄 끝마다 \만 붙여주기'''
fi_str = "0.03546066 0.03446177 0.43028001 0.49979756"
 
''' str에서 숫자로 변환하는 구간 '''
fi_str = fi_str.split()
fi_float = [float(s) for s in fi_str]
print(fi_float)
fi_list = pd.Series(fi_float)

''' 25퍼 미만 인덱스 구하기 '''
low_idx_list = fi_list[fi_list <= fi_list.quantile(0.25)].index
print('low_idx_list',low_idx_list)

''' 25퍼 미만 제거하기 '''
low_col_list = [x.columns[index] for index in low_idx_list]
# 이건 혹여 중복되는 값들이 많아 25퍼이상으로 넘어갈시 25퍼로 자르기
if len(low_col_list) > len(x.columns) * 0.25:   
    low_col_list = low_col_list[:int(len(x.columns)*0.25)]
print('low_col_list',low_col_list)
x.drop(low_col_list,axis=1,inplace=True)
print("after x.shape",x.shape)


x_train, x_test , y_train , y_test = train_test_split(x,y,test_size= 0.3 , random_state= 123 , stratify=y , shuffle=True)


kfold = StratifiedKFold(n_splits= 3 , shuffle=True , random_state= 1234 )

parameters =[
    {'n_estimators' : [100,200] ,'max_depth':[6,10,12],'min_samples_leaf' : [3,10]},
    {'max_depth': [6,8,10,12], 'min_samples_leaf' : [3,5,7,10]},
    {'min_samples_leaf' : [3,5,7,10],'min_samples_split' : [2,3,5,10]},
    {'min_samples_split' : [2,3,5,10] },
    {'n_jobs' : [-1,2,4], 'min_samples_split' : [2,3,5,10]}
]
#2 모델
from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier , DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor , GradientBoostingClassifier
from xgboost import XGBRegressor , XGBClassifier
models = [DecisionTreeClassifier(random_state = 777), RandomForestClassifier(random_state = 777) , 
          GradientBoostingClassifier(random_state = 777),XGBClassifier()]

############## 훈련 반복 for 문 ###################a
for model in models :
    model.fit(x_train,y_train)
    result = model.score(x_test,y_test)
    print(type(model).__name__,':',model.feature_importances_ ,result)
   # y_predict = model.predict(x_test)
    print(type(model).__name__,'result',result)
    
    
# DecisionTreeRegressor : [0.00000000e+00 1.19788794e-03 2.32869416e-03 6.46859489e-05
#  5.09234479e-03 1.42309088e-04 1.73676404e-02 6.46859489e-05
#  0.00000000e+00 4.36630155e-04 6.35233539e-03 9.55304546e-03
#  2.60503520e-02 1.15389640e-02 0.00000000e+00 0.00000000e+00
#  0.00000000e+00 2.34214078e-03 8.36329525e-03 2.64319046e-02
#  8.79939183e-02 6.29334420e-02 3.52136815e-03 0.00000000e+00
#  0.00000000e+00 3.60997184e-03 2.16373552e-02 5.81577023e-02
#  1.74079211e-02 5.34096823e-02 1.11589222e-02 0.00000000e+00
#  0.00000000e+00 1.01036999e-02 5.22494612e-02 4.48573880e-02
#  8.89934597e-02 2.88617211e-03 1.95993894e-02 0.00000000e+00
#  0.00000000e+00 8.51878169e-04 8.96259119e-02 6.51722546e-03
#  5.46521073e-03 1.28845413e-03 1.77886360e-04 0.00000000e+00
#  0.00000000e+00 3.74774217e-03 5.03783007e-03 8.71172355e-03
#  1.28955080e-01 1.20982744e-02 9.09958423e-03 0.00000000e+00
#  0.00000000e+00 0.00000000e+00 2.70434837e-03 6.12414996e-03
#  4.04848629e-03 4.37802002e-04 5.45566731e-02 4.70496982e-03] 0.6805478896561046
# DecisionTreeRegressor result 0.6805478896561046
# RandomForestClassifier : [0.00000000e+00 2.67271629e-03 2.03369293e-02 1.09688334e-02
#  1.02041920e-02 1.70846458e-02 8.27423781e-03 9.46258253e-04
#  1.17937307e-05 1.03827730e-02 2.45604247e-02 8.35144538e-03
#  1.81453445e-02 3.12186000e-02 5.38423251e-03 9.37856439e-04
#  6.84444457e-05 7.44943820e-03 2.01726031e-02 2.55626244e-02
#  3.05934958e-02 4.89337034e-02 8.54295161e-03 2.77232030e-04
#  2.35815043e-05 1.15209090e-02 4.16725284e-02 2.42999954e-02
#  3.10803881e-02 2.30355028e-02 3.05413332e-02 0.00000000e+00
#  0.00000000e+00 3.34968761e-02 3.03246479e-02 2.00145902e-02
#  3.97389749e-02 1.74726322e-02 2.20444604e-02 0.00000000e+00
#  1.64763561e-05 1.00085435e-02 3.39415808e-02 4.32136481e-02
#  1.87354748e-02 1.82331014e-02 1.98899597e-02 3.64216763e-05
#  6.70664671e-05 2.89478229e-03 1.63742742e-02 2.18872551e-02
#  1.49113864e-02 2.59244477e-02 2.75664171e-02 1.65456646e-03
#  3.03469749e-05 2.32357380e-03 2.15756039e-02 1.09705209e-02
#  2.22318796e-02 2.88559391e-02 1.69304476e-02 5.37908975e-03] 0.9833333333333333
# RandomForestClassifier result 0.9833333333333333
# GradientBoostingRegressor : [0.00000000e+00 2.49050588e-04 2.91268951e-03 5.41582138e-03
#  2.52192947e-03 4.72904384e-03 3.04889304e-03 4.21389588e-04
#  6.22810528e-04 1.02359078e-03 7.48613698e-03 2.80834709e-03
#  3.79918235e-02 4.23855374e-03 3.30914866e-03 0.00000000e+00
#  1.17664865e-04 6.26218007e-04 2.69644997e-02 8.21702312e-03
#  7.30103652e-02 6.40919185e-02 1.92501327e-02 0.00000000e+00
#  0.00000000e+00 5.14290139e-03 1.34292494e-02 5.41873520e-02
#  3.39487899e-02 4.05838512e-02 3.35608546e-02 6.87277824e-04
#  0.00000000e+00 4.07488115e-02 2.24842061e-02 5.43325614e-02
#  1.08669426e-01 6.95707405e-03 4.01219900e-03 0.00000000e+00
#  0.00000000e+00 1.32810080e-03 4.05953725e-02 1.53652981e-02
#  6.19703691e-03 6.22693447e-03 2.98371022e-03 0.00000000e+00
#  0.00000000e+00 5.16528584e-04 4.20947561e-03 2.86044674e-02
#  1.18882974e-01 4.46103321e-03 2.39539144e-03 1.17960923e-04
#  0.00000000e+00 0.00000000e+00 4.00784622e-03 3.02909829e-03
#  1.95338761e-02 1.62061451e-02 2.83993456e-02 9.13779954e-03] 0.8317676524912937
# GradientBoostingRegressor result 0.8317676524912937
# XGBRegressor : [0.00000000e+00 1.47608703e-03 1.50635210e-03 3.00840242e-03
#  2.35054293e-03 6.22169720e-03 2.01174654e-02 5.12948586e-03
#  4.40686708e-03 1.08695321e-03 7.65913539e-03 4.42709075e-03
#  2.62229107e-02 1.31302159e-02 2.30310950e-03 3.26854934e-05
#  0.00000000e+00 2.23149941e-03 1.05105946e-02 9.65185929e-03
#  5.10084778e-02 4.55481037e-02 2.00712625e-02 1.38275809e-05
#  0.00000000e+00 5.36837196e-03 1.34400185e-02 2.65336111e-02
#  3.62011902e-02 5.40450886e-02 1.85854118e-02 0.00000000e+00
#  0.00000000e+00 3.21253501e-02 4.05683778e-02 2.60584820e-02
#  7.59148076e-02 4.73504746e-03 1.99724846e-02 0.00000000e+00
#  0.00000000e+00 2.29958398e-03 5.26881404e-02 2.62657776e-02
#  5.05139166e-03 1.20129185e-02 1.13802776e-02 1.64358480e-05
#  0.00000000e+00 3.04543762e-03 5.95460040e-03 1.16790924e-02
#  9.22656953e-02 3.88749992e-03 3.63704073e-03 2.12430750e-04
#  0.00000000e+00 1.61234336e-03 1.90064451e-03 6.26184233e-03
#  1.93637051e-02 6.51767664e-03 1.08577296e-01 3.37073319e-02] 0.8702070735856834
# XGBRegressor result 0.8702070735856834




# DecisionTreeClassifier : [0.         0.01845518 0.01003328 0.00294653 0.06492064 0.00141433
#  0.00088396 0.         0.00411978 0.00474609 0.00520554 0.02513115
#  0.01718183 0.0022099  0.         0.00088396 0.00506015 0.01146932
#  0.02399097 0.03936946 0.09437311 0.00132594 0.         0.00174969
#  0.         0.05109683 0.0484327  0.00866569 0.01753775 0.01095132
#  0.         0.         0.05359899 0.01297876 0.00240935 0.07697322
#  0.0327761  0.00486739 0.         0.         0.0025256  0.12225082
#  0.05341002 0.01725575 0.00804747 0.00592538 0.         0.
#  0.00141433 0.00358073 0.00449346 0.00839678 0.01421306 0.02169172
#  0.         0.         0.         0.00489124 0.00753648 0.06256754
#  0.         0.         0.0060407 ] 0.8425925925925926
# DecisionTreeClassifier result 0.8425925925925926
# RandomForestClassifier : [0.00000000e+00 2.21634755e-02 1.27156654e-02 1.04638666e-02
#  1.88056540e-02 9.55266652e-03 7.30683665e-04 1.02928920e-04
#  1.17848044e-02 2.25546360e-02 9.14527565e-03 1.58920147e-02
#  2.68621595e-02 5.76224372e-03 4.91659062e-04 1.05454501e-04
#  9.21639739e-03 2.04351253e-02 2.78328599e-02 2.75797297e-02
#  4.67744069e-02 9.63965221e-03 2.01673042e-04 1.00601195e-04
#  1.37421711e-02 4.06084993e-02 2.44905295e-02 2.67904590e-02
#  2.47441154e-02 3.10727320e-02 4.00832502e-05 0.00000000e+00
#  3.02528789e-02 3.34142041e-02 1.65760002e-02 4.26275446e-02
#  2.17247815e-02 2.34696037e-02 0.00000000e+00 7.21019830e-05
#  1.12372157e-02 3.40480444e-02 3.77218452e-02 2.24350740e-02
#  1.81122937e-02 1.80348036e-02 1.88173269e-04 1.70330577e-05
#  3.52480949e-03 1.90359249e-02 2.55913210e-02 1.33634996e-02
#  2.17132981e-02 2.30675554e-02 2.53347372e-03 2.77158153e-05
#  2.00282494e-03 2.25587774e-02 1.14302261e-02 2.55976396e-02
#  3.05550580e-02 1.61811027e-02 2.48295252e-03] 0.9777777777777777
# RandomForestClassifier result 0.9777777777777777
# GradientBoostingClassifier : [0.00000000e+00 1.11727296e-02 5.45910474e-03 1.77671976e-03
#  5.21224470e-02 3.90494450e-03 1.15942525e-03 2.25169308e-04
#  5.27503992e-03 1.82834818e-02 1.91648479e-03 8.81507481e-03
#  1.33468093e-02 3.17734082e-03 9.91300419e-04 2.92678242e-04
#  2.84512130e-03 1.50994265e-02 3.99220755e-02 1.92163919e-02
#  9.94850082e-02 3.26126376e-03 1.98904397e-07 1.44905803e-05
#  6.24945002e-04 4.16308230e-02 2.00635793e-02 1.98765114e-02
#  2.40164236e-02 9.32735536e-03 5.96949563e-04 0.00000000e+00
#  7.26222426e-02 3.32123124e-03 5.82735033e-03 7.06430024e-02
#  1.41339565e-02 1.57352982e-02 0.00000000e+00 4.24065882e-10
#  5.16244913e-03 8.74174752e-02 6.99779424e-02 1.47409953e-02
#  1.85030221e-02 2.93986559e-02 6.14784857e-04 1.68761697e-08
#  6.07468777e-03 3.36423495e-03 8.30827019e-03 5.13147705e-03
#  9.74366936e-03 2.62593421e-02 2.37087580e-04 8.01457664e-04
#  1.92142711e-04 9.21879135e-03 1.15455871e-03 5.81497950e-02
#  1.31477584e-02 1.89222370e-02 7.29675258e-03] 0.9648148148148148
# GradientBoostingClassifier result 0.9648148148148148
# XGBClassifier : [0.         0.01928995 0.01175664 0.00375387 0.04429682 0.00684091
#  0.00606    0.         0.01775649 0.01232052 0.00655086 0.00697777
#  0.01289279 0.00143017 0.01092    0.         0.00612615 0.00783572
#  0.04429343 0.01148528 0.05223944 0.00427167 0.00354157 0.
#  0.0094311  0.03415259 0.00943977 0.01731162 0.0194812  0.01937478
#  0.         0.         0.08180211 0.00614494 0.00639577 0.05327758
#  0.01620478 0.03116516 0.         0.         0.00502144 0.03964743
#  0.0455553  0.01033674 0.02049515 0.03497794 0.         0.
#  0.01236656 0.00471209 0.00563262 0.01232069 0.0152804  0.02728898
#  0.00369769 0.         0.01614358 0.01729068 0.00562296 0.06195748
#  0.02006587 0.0253037  0.02146135] 0.9685185185185186
# XGBClassifier result 0.9685185185185186